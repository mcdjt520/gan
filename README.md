# gan
gan zoo test
Generative Adversarial Nets, or GAN in short,
is a quite popular neural net. 
It was first introduced in a NIPS 2014 paper by Ian Goodfellow,
et al. This paper literally sparked a lot of interest in adversarial training of neural net, 
proved by the number of citation of the paper. Suddenly, 
many flavors of GAN came up: DCGAN, Sequence-GAN, LSTM-GAN, etc.
In NIPS 2016, there will even be a whole workshop dedicated for adversarial training!

生成对抗性网络(简称 GAN)是一种相当流行的神经网络。 
它最早是由 Ian Goodfellow 等人在2014年的 NIPS 论文中介绍的。
本文引用的论文数量证明，引起了人们对神经网络对抗性训练的极大兴趣。 
突然间，GAN 的许多风格出现了: DCGAN、序列 GAN、 lstm-GAN 等等。 
在 NIPS 2016年，甚至将有一个专门的对抗培训的整个工作坊！

Generative Adversarial Nets
生成对抗网
Let’s consider the rosy relationship between a money conterfeiting criminal and a cop.
What’s the objective of the criminal and what’s the objective of the cop in term of counterfeited money? Let’s enumerate:

让我们考虑一下金钱纵容罪犯和警察之间的美好关系。 犯罪分子的目的是什么，警察对假币的目的又是什么？ 让我们列举一下:

To be a successful money counterfeiter, the criminal wants to fool the cop, 
so that the cop can’t tell the difference between counterfeited money and real money 
为了成为一个成功的金钱伪造者，罪犯想要愚弄警察，这样警察就分不清假钱和真钱了
To be a paragon of justice, the cop wants to detect counterfeited money as good as possible 
作为正义的典范，警察要尽可能好地侦破假币
There, we see we have a clash of interest. This kind of situation could be modeled as a minimax game in Game Theory.
And this process is called Adversarial Process.

在那里，我们看到了利益的冲突。 这种情况可以用博弈论中的极大极小博弈来模拟。 这个过程叫做对抗过程。

Generative Adversarial Nets (GAN), 
is a special case of Adversarial Process where the components (the cop and the criminal) are neural net. 
The first net generates data, 
and the second net tries to tell the difference between the real data and the fake data generated by the first net. 
The second net will output a scalar [0, 1] which represents a probability of real data.

生成对抗网(GAN)是对抗过程的一种特殊情况，其组成部分(警察和犯罪分子)是神经网络。 
第一个网络产生数据，第二个网络试图区分第一个网络产生的真实数据和伪造数据之间的差异。
第二个净值将输出一个标量[0,1] ，它表示实际数据的概率。

In GAN, the first net is called Generator Net G(Z)
 and the second net called Discriminator Net D(X).

在 GAN 中，第一个网称为生成网 g (z)  ，第二个网称为鉴别网 d (x) 。

GAN Value Function

At the equilibrium point, 
which is the optimal point in minimax game, 
the first net will models the real data, 
and the second net will output probability of 0.5 as the output of the first net = real data.

在极大极小博弈的最优点---- 平衡点，第一个网络将对实际数据进行建模，第二个网络将输出0.5的概率作为第一个净实际数据的输出。

“BTW why do we interested in training GAN?” might come in mind. It’s because probability distribution of data Pdata
 might be a very complicated distribution and very hard and intractable to infer.
 So, having a generative machine that could generate samples from data
 without having to deal with nasty probability distribution is very nice.
 If we have this, then we could use it for another process that require sample from Pdata
 as we could get samples relatively cheaply using the trained Generative Net.

“顺便说一句，为什么我们对培训 GAN 感兴趣? ” 
可能会想到。 这是因为数据的概率分布可能是一个非常复杂的分布，非常难以推断。
因此，拥有一台可以从 Pdata 的 p d a t 生成样本的生成机器，而不必处理令人讨厌的概率分布是非常好的。
如果我们有了这个，那么我们就可以用它来做另一个需要从 Pdata 获取样本的过程，因为我们可以使用训练有素的生成网获得相对便宜的样本。
